{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5794f5ee",
   "metadata": {},
   "source": [
    "## Deploy de modelo com o Triton Inference Server"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef16ce49",
   "metadata": {},
   "source": [
    "## Pré requisitos\n",
    "- Podman\n",
    "- Notebook python"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f11fa374",
   "metadata": {},
   "source": [
    "## Explicando a estrutura dos modelos na Triton"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a1b11382",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Folder PATH listing for volume OS\n",
      "Volume serial number is 6037-BFFF\n",
      "C:\\USERS\\018117631\\DOCUMENTS\\PROJETO BB\\TRITON\\PROJETO_TRITON\\TRITON\\MODELO_REGRESSAO\n",
      "+---1\n",
      "    +---__pycache__\n"
     ]
    }
   ],
   "source": [
    "!tree modelo_regressao"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05867e6f",
   "metadata": {},
   "source": [
    "## Config.pbxt - Protobuffer\n",
    "O arquivo de de configuração do config.pbtxt especifica as entradas e saídas dos modelos:\n",
    "- As entradas são os dados que o modelo recebe para realizar a inferência. \n",
    "- As saídas são os resultados da inferência do modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "02f09f82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "backend: \"python\"\n",
      "\n",
      "input {\n",
      "    name: \"input\"\n",
      "    data_type: TYPE_FP32\n",
      "    dims: [-1, -1]\n",
      "}\n",
      "\n",
      "output {\n",
      "    name: \"PREDICAO\"\n",
      "    data_type: TYPE_STRING\n",
      "    dims: [ 1 ]\n",
      "}\n",
      "\n",
      "instance_group [{ kind: KIND_CPU }]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open('./modelo_regressao/config.pbtxt', 'r') as f:\n",
    "    arquivo_configuracao = f.read()\n",
    "\n",
    "print(arquivo_configuracao)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3abf8e4",
   "metadata": {},
   "source": [
    "## Model.py \n",
    "- O arquivo model.py contém o código para carregar o modelo com base nas configurações fornecidas pelo protobuffer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cd829f09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "import json\n",
      "\n",
      "import numpy as np\n",
      "import triton_python_backend_utils as pb_utils\n",
      "from joblib import load\n",
      "\n",
      "\n",
      "class TritonPythonModel:\n",
      "    def initialize(self, args):\n",
      "        self.model_config = model_config = json.loads(args['model_config'])\n",
      "\n",
      "        predicao_config = pb_utils.get_output_config_by_name(\n",
      "            model_config, \"PREDICAO\")\n",
      "        \n",
      "        self.predicao_dtype = pb_utils.triton_string_to_numpy(\n",
      "            predicao_config['data_type'])\n",
      "\n",
      "        version_path =  args['model_repository'] + '/' + args['model_version']\n",
      "\n",
      "        self.model = load(version_path + '/model.pickle')\n",
      "\n",
      "    def execute(self, requests):\n",
      "        responses = []\n",
      "\n",
      "        for request in requests:\n",
      "            in_0 = pb_utils.get_input_tensor_by_name(request, \"input\")\n",
      "\n",
      "            input_0 = in_0.as_numpy()\n",
      "\n",
      "            predicao = self.model.predict(input_0)\n",
      "\n",
      "            predicao_tensor = pb_utils.Tensor(\n",
      "                \"PREDICAO\", predicao.astype(self.predicao_dtype))\n",
      "\n",
      "            inference_response = pb_utils.InferenceResponse(\n",
      "                output_tensors=[predicao_tensor])\n",
      "            responses.append(inference_response)\n",
      "\n",
      "        return responses\n",
      "\n",
      "    def finalize(self):\n",
      "        print('Cleaning up...')\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open('./modelo_regressao/1/model.py', 'r') as f:\n",
    "    arquivo_modelo = f.read()\n",
    "\n",
    "print(arquivo_modelo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e72dc00e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scikit-learn===0.24.0\n",
      "  Downloading scikit-learn-0.24.0.tar.gz (7.4 MB)\n",
      "     ---------------------------------------- 0.0/7.4 MB ? eta -:--:--\n",
      "     ---------------------------------------- 0.1/7.4 MB 1.1 MB/s eta 0:00:07\n",
      "     - -------------------------------------- 0.2/7.4 MB 2.8 MB/s eta 0:00:03\n",
      "     -- ------------------------------------- 0.5/7.4 MB 3.8 MB/s eta 0:00:02\n",
      "     --- ------------------------------------ 0.7/7.4 MB 3.9 MB/s eta 0:00:02\n",
      "     --- ------------------------------------ 0.7/7.4 MB 4.2 MB/s eta 0:00:02\n",
      "     ---- ----------------------------------- 0.8/7.4 MB 3.1 MB/s eta 0:00:03\n",
      "     ------- -------------------------------- 1.3/7.4 MB 4.2 MB/s eta 0:00:02\n",
      "     --------- ------------------------------ 1.8/7.4 MB 5.1 MB/s eta 0:00:02\n",
      "     ------------ --------------------------- 2.4/7.4 MB 5.8 MB/s eta 0:00:01\n",
      "     -------------- ------------------------- 2.7/7.4 MB 6.0 MB/s eta 0:00:01\n",
      "     ----------------- ---------------------- 3.3/7.4 MB 6.5 MB/s eta 0:00:01\n",
      "     ------------------- -------------------- 3.7/7.4 MB 6.7 MB/s eta 0:00:01\n",
      "     ---------------------- ----------------- 4.2/7.4 MB 7.0 MB/s eta 0:00:01\n",
      "     ---------------------- ----------------- 4.2/7.4 MB 7.0 MB/s eta 0:00:01\n",
      "     ------------------------- -------------- 4.7/7.4 MB 6.8 MB/s eta 0:00:01\n",
      "     ---------------------------- ----------- 5.2/7.4 MB 7.1 MB/s eta 0:00:01\n",
      "     ------------------------------ --------- 5.7/7.4 MB 7.5 MB/s eta 0:00:01\n",
      "     --------------------------------- ------ 6.3/7.4 MB 7.7 MB/s eta 0:00:01\n",
      "     ------------------------------------ --- 6.8/7.4 MB 7.9 MB/s eta 0:00:01\n",
      "     ---------------------------------------  7.3/7.4 MB 8.1 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 7.4/7.4 MB 7.8 MB/s eta 0:00:00\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\users\\018117631\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from scikit-learn===0.24.0) (1.4.0)\n",
      "Requirement already satisfied: numpy>=1.13.3 in c:\\users\\018117631\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from scikit-learn===0.24.0) (1.26.4)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\018117631\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from scikit-learn===0.24.0) (3.4.0)\n",
      "Requirement already satisfied: scipy>=0.19.1 in c:\\users\\018117631\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from scikit-learn===0.24.0) (1.13.0)\n",
      "Building wheels for collected packages: scikit-learn\n",
      "  Building wheel for scikit-learn (pyproject.toml): started\n",
      "  Building wheel for scikit-learn (pyproject.toml): finished with status 'error'\n",
      "Failed to build scikit-learn\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  error: subprocess-exited-with-error\n",
      "  \n",
      "  × Building wheel for scikit-learn (pyproject.toml) did not run successfully.\n",
      "  │ exit code: 1\n",
      "  ╰─> [56 lines of output]\n",
      "      <string>:17: DeprecationWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html\n",
      "      Partial import of sklearn during the build process.\n",
      "      <string>:116: DeprecationWarning:\n",
      "      \n",
      "        `numpy.distutils` is deprecated since NumPy 1.23.0, as a result\n",
      "        of the deprecation of `distutils` itself. It will be removed for\n",
      "        Python >= 3.12. For older Python versions it will remain present.\n",
      "        It is recommended to use `setuptools < 60.0` for those Python versions.\n",
      "        For more details, see:\n",
      "          https://numpy.org/devdocs/reference/distutils_status_migration.html\n",
      "      \n",
      "      \n",
      "      INFO: No module named 'numpy.distutils._msvccompiler' in numpy.distutils; trying from distutils\n",
      "      Traceback (most recent call last):\n",
      "        File \"C:\\Users\\018117631\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pip\\_vendor\\pyproject_hooks\\_in_process\\_in_process.py\", line 353, in <module>\n",
      "          main()\n",
      "        File \"C:\\Users\\018117631\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pip\\_vendor\\pyproject_hooks\\_in_process\\_in_process.py\", line 335, in main\n",
      "          json_out['return_val'] = hook(**hook_input['kwargs'])\n",
      "        File \"C:\\Users\\018117631\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pip\\_vendor\\pyproject_hooks\\_in_process\\_in_process.py\", line 251, in build_wheel\n",
      "          return _build_backend().build_wheel(wheel_directory, config_settings,\n",
      "        File \"C:\\Users\\018117631\\AppData\\Local\\Temp\\pip-build-env-mxkim0rv\\overlay\\Lib\\site-packages\\setuptools\\build_meta.py\", line 410, in build_wheel\n",
      "          return self._build_with_temp_dir(\n",
      "        File \"C:\\Users\\018117631\\AppData\\Local\\Temp\\pip-build-env-mxkim0rv\\overlay\\Lib\\site-packages\\setuptools\\build_meta.py\", line 395, in _build_with_temp_dir\n",
      "          self.run_setup()\n",
      "        File \"C:\\Users\\018117631\\AppData\\Local\\Temp\\pip-build-env-mxkim0rv\\overlay\\Lib\\site-packages\\setuptools\\build_meta.py\", line 487, in run_setup\n",
      "          super().run_setup(setup_script=setup_script)\n",
      "        File \"C:\\Users\\018117631\\AppData\\Local\\Temp\\pip-build-env-mxkim0rv\\overlay\\Lib\\site-packages\\setuptools\\build_meta.py\", line 311, in run_setup\n",
      "          exec(code, locals())\n",
      "        File \"<string>\", line 306, in <module>\n",
      "        File \"<string>\", line 302, in setup_package\n",
      "        File \"C:\\Users\\018117631\\AppData\\Local\\Temp\\pip-build-env-mxkim0rv\\overlay\\Lib\\site-packages\\numpy\\distutils\\core.py\", line 136, in setup\n",
      "          config = configuration()\n",
      "        File \"<string>\", line 188, in configuration\n",
      "        File \"C:\\Users\\018117631\\AppData\\Local\\Temp\\pip-build-env-mxkim0rv\\overlay\\Lib\\site-packages\\numpy\\distutils\\misc_util.py\", line 1050, in add_subpackage\n",
      "          config_list = self.get_subpackage(subpackage_name, subpackage_path,\n",
      "        File \"C:\\Users\\018117631\\AppData\\Local\\Temp\\pip-build-env-mxkim0rv\\overlay\\Lib\\site-packages\\numpy\\distutils\\misc_util.py\", line 1016, in get_subpackage\n",
      "          config = self._get_configuration_from_setup_py(\n",
      "        File \"C:\\Users\\018117631\\AppData\\Local\\Temp\\pip-build-env-mxkim0rv\\overlay\\Lib\\site-packages\\numpy\\distutils\\misc_util.py\", line 958, in _get_configuration_from_setup_py\n",
      "          config = setup_module.configuration(*args)\n",
      "        File \"C:\\Users\\018117631\\AppData\\Local\\Temp\\pip-install-lh98ms7w\\scikit-learn_b3b600ce4b074d7287dd9df8ff162ef0\\sklearn\\setup.py\", line 83, in configuration\n",
      "          cythonize_extensions(top_path, config)\n",
      "        File \"C:\\Users\\018117631\\AppData\\Local\\Temp\\pip-install-lh98ms7w\\scikit-learn_b3b600ce4b074d7287dd9df8ff162ef0\\sklearn\\_build_utils\\__init__.py\", line 45, in cythonize_extensions\n",
      "          basic_check_build()\n",
      "        File \"C:\\Users\\018117631\\AppData\\Local\\Temp\\pip-install-lh98ms7w\\scikit-learn_b3b600ce4b074d7287dd9df8ff162ef0\\sklearn\\_build_utils\\pre_build_helpers.py\", line 106, in basic_check_build\n",
      "          compile_test_program(code)\n",
      "        File \"C:\\Users\\018117631\\AppData\\Local\\Temp\\pip-install-lh98ms7w\\scikit-learn_b3b600ce4b074d7287dd9df8ff162ef0\\sklearn\\_build_utils\\pre_build_helpers.py\", line 66, in compile_test_program\n",
      "          ccompiler.compile(['test_program.c'], output_dir='objects',\n",
      "        File \"C:\\Users\\018117631\\AppData\\Local\\Temp\\pip-build-env-mxkim0rv\\overlay\\Lib\\site-packages\\setuptools\\_distutils\\_msvccompiler.py\", line 343, in compile\n",
      "          self.initialize()\n",
      "        File \"C:\\Users\\018117631\\AppData\\Local\\Temp\\pip-build-env-mxkim0rv\\overlay\\Lib\\site-packages\\setuptools\\_distutils\\_msvccompiler.py\", line 253, in initialize\n",
      "          vc_env = _get_vc_env(plat_spec)\n",
      "        File \"C:\\Users\\018117631\\AppData\\Local\\Temp\\pip-build-env-mxkim0rv\\overlay\\Lib\\site-packages\\setuptools\\msvc.py\", line 230, in msvc14_get_vc_env\n",
      "          return _msvc14_get_vc_env(plat_spec)\n",
      "        File \"C:\\Users\\018117631\\AppData\\Local\\Temp\\pip-build-env-mxkim0rv\\overlay\\Lib\\site-packages\\setuptools\\msvc.py\", line 187, in _msvc14_get_vc_env\n",
      "          raise distutils.errors.DistutilsPlatformError(\"Unable to find vcvarsall.bat\")\n",
      "      distutils.errors.DistutilsPlatformError: Microsoft Visual C++ 14.0 or greater is required. Get it with \"Microsoft C++ Build Tools\": https://visualstudio.microsoft.com/visual-cpp-build-tools/\n",
      "      [end of output]\n",
      "  \n",
      "  note: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "  ERROR: Failed building wheel for scikit-learn\n",
      "ERROR: Could not build wheels for scikit-learn, which is required to install pyproject.toml-based projects\n",
      "\n",
      "[notice] A new release of pip is available: 23.0.1 -> 24.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "# !pip install scikit-learn===1.1.1\n",
    "!pip install scikit-learn===0.24.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1d0048ff",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "node array from the pickle has an incompatible dtype:\n- expected: {'names': ['left_child', 'right_child', 'feature', 'threshold', 'impurity', 'n_node_samples', 'weighted_n_node_samples', 'missing_go_to_left'], 'formats': ['<i8', '<i8', '<i8', '<f8', '<f8', '<i8', '<f8', 'u1'], 'offsets': [0, 8, 16, 24, 32, 40, 48, 56], 'itemsize': 64}\n- got     : [('left_child', '<i8'), ('right_child', '<i8'), ('feature', '<i8'), ('threshold', '<f8'), ('impurity', '<f8'), ('n_node_samples', '<i8'), ('weighted_n_node_samples', '<f8')]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[30], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpickle\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./modelo_regressao/1/model.pickle\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m----> 4\u001b[0m     modelo \u001b[38;5;241m=\u001b[39m \u001b[43mpickle\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# print(type(modelo))\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# print(modelo)\u001b[39;00m\n",
      "File \u001b[1;32msklearn\\\\tree\\\\_tree.pyx:865\u001b[0m, in \u001b[0;36msklearn.tree._tree.Tree.__setstate__\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32msklearn\\\\tree\\\\_tree.pyx:1571\u001b[0m, in \u001b[0;36msklearn.tree._tree._check_node_ndarray\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: node array from the pickle has an incompatible dtype:\n- expected: {'names': ['left_child', 'right_child', 'feature', 'threshold', 'impurity', 'n_node_samples', 'weighted_n_node_samples', 'missing_go_to_left'], 'formats': ['<i8', '<i8', '<i8', '<f8', '<f8', '<i8', '<f8', 'u1'], 'offsets': [0, 8, 16, 24, 32, 40, 48, 56], 'itemsize': 64}\n- got     : [('left_child', '<i8'), ('right_child', '<i8'), ('feature', '<i8'), ('threshold', '<f8'), ('impurity', '<f8'), ('n_node_samples', '<i8'), ('weighted_n_node_samples', '<f8')]"
     ]
    }
   ],
   "source": [
    "# Deserializando .pickle do modelo para entender o tipo de modelo\n",
    "# https://docs.python.org/3/library/pickle.html\n",
    "import pickle\n",
    "\n",
    "with open('./modelo_regressao/1/model.pickle', 'rb') as f:\n",
    "    modelo = pickle.load(f)\n",
    "\n",
    "print(type(modelo))\n",
    "# print(modelo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b151b08f",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "node array from the pickle has an incompatible dtype:\n- expected: {'names': ['left_child', 'right_child', 'feature', 'threshold', 'impurity', 'n_node_samples', 'weighted_n_node_samples', 'missing_go_to_left'], 'formats': ['<i8', '<i8', '<i8', '<f8', '<f8', '<i8', '<f8', 'u1'], 'offsets': [0, 8, 16, 24, 32, 40, 48, 56], 'itemsize': 64}\n- got     : [('left_child', '<i8'), ('right_child', '<i8'), ('feature', '<i8'), ('threshold', '<f8'), ('impurity', '<f8'), ('n_node_samples', '<i8'), ('weighted_n_node_samples', '<f8')]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[27], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Carregar o objeto do arquivo .pickle\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./modelo_regressao/1/model.pickle\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m----> 5\u001b[0m     objeto \u001b[38;5;241m=\u001b[39m \u001b[43mpickle\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# Escrever o código Python para reproduzir o objeto no arquivo .py\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# with open('resultado_modelo.py', 'w') as f:\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m#     f.write(\"import pickle\\n\\n\")\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m#     f.write(repr(objeto))\u001b[39;00m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m#     f.write(\"\\n\")\u001b[39;00m\n",
      "File \u001b[1;32msklearn\\\\tree\\\\_tree.pyx:865\u001b[0m, in \u001b[0;36msklearn.tree._tree.Tree.__setstate__\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32msklearn\\\\tree\\\\_tree.pyx:1571\u001b[0m, in \u001b[0;36msklearn.tree._tree._check_node_ndarray\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: node array from the pickle has an incompatible dtype:\n- expected: {'names': ['left_child', 'right_child', 'feature', 'threshold', 'impurity', 'n_node_samples', 'weighted_n_node_samples', 'missing_go_to_left'], 'formats': ['<i8', '<i8', '<i8', '<f8', '<f8', '<i8', '<f8', 'u1'], 'offsets': [0, 8, 16, 24, 32, 40, 48, 56], 'itemsize': 64}\n- got     : [('left_child', '<i8'), ('right_child', '<i8'), ('feature', '<i8'), ('threshold', '<f8'), ('impurity', '<f8'), ('n_node_samples', '<i8'), ('weighted_n_node_samples', '<f8')]"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "# Carregar o objeto do arquivo .pickle\n",
    "with open('./modelo_regressao/1/model.pickle', 'rb') as f:\n",
    "    objeto = pickle.load(f)\n",
    "\n",
    "# Escrever o código Python para reproduzir o objeto no arquivo .py\n",
    "# with open('resultado_modelo.py', 'w') as f:\n",
    "#     f.write(\"import pickle\\n\\n\")\n",
    "#     f.write(\"# Código para reproduzir o objeto\\n\")\n",
    "#     f.write(\"objeto = \")\n",
    "#     f.write(repr(objeto))\n",
    "#     f.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62585c81",
   "metadata": {},
   "source": [
    "## Deploy do modelo na triton usando o podman"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55792a2b",
   "metadata": {},
   "source": [
    "Imagem do triton mais recente: 23.09-py3\n",
    "\n",
    "`podman pull nvcr.io/nvidia/tritonserver:23.09-py3`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfbaa038",
   "metadata": {},
   "source": [
    "No terminal, executar o comando:\n",
    "\n",
    "`podman run --rm -p 8000:8000 -v $HOME/triton:/models nvcr.io/nvidia/tritonserver:23.09-py3 /bin/bash -c \"pip install -r /models/requirements.txt && tritonserver --model-repository=/models\"`\n",
    "\n",
    "\n",
    "O que faz esse comado:\n",
    "\n",
    "- Executa um contêiner usando o podman, mapeando a porta 8000 do host para a porta 8000 do contêiner e montando o diretório $HOME/triton do host para /models dentro do contêiner. \n",
    "- Instala o requirements (bibliotecas necessárias) para o modelo."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd6cd360",
   "metadata": {},
   "source": [
    "## Após o deploy, vamos realizar inferências!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "68fcffb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[11.1]]\n",
      "{\"model_name\":\"modelo_regressao\",\"model_version\":\"1\",\"outputs\":[{\"name\":\"PREDICAO\",\"datatype\":\"BYTES\",\"shape\":[1],\"data\":[\"121873.0\"]}]}\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "import numpy as np\n",
    "\n",
    "url = \"http://localhost:8000/v2/models/modelo_regressao/versions/1/infer\"\n",
    "\n",
    "\n",
    "# input data\n",
    "input_data = np.array([11.1]).reshape(-1, 1)\n",
    "# input_data = np.array([10.1]).reshape(-1, 1)\n",
    "print(input_data)\n",
    "payload = json.dumps({\n",
    "  \"inputs\": [\n",
    "    {\n",
    "      # \"name\": \"ENTRADA\",\n",
    "      \"name\": \"input\",\n",
    "      \"shape\": input_data.shape,\n",
    "      \"datatype\": \"FP32\",\n",
    "      \"data\": input_data.tolist()\n",
    "    }\n",
    "  ]\n",
    "})\n",
    "\n",
    "headers = {\n",
    "  'Content-Type': 'application/json'\n",
    "}\n",
    "\n",
    "response = requests.request(\"POST\", url, headers=headers, data=payload)\n",
    "\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dd0ed15",
   "metadata": {},
   "source": [
    "## Comandinhos de verificação"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac49923b",
   "metadata": {},
   "source": [
    "> É necessário utilizar a versão 3.10.11 do Python para instalar as bibiliotecas a seguir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdfed8d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tritonclient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "799c0807",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install gevent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9f42206a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting geventhttpclient==1.5.4\n",
      "  Downloading geventhttpclient-1.5.4-cp310-cp310-win_amd64.whl (37 kB)\n",
      "Requirement already satisfied: six in c:\\users\\018117631\\appdata\\roaming\\python\\python310\\site-packages (from geventhttpclient==1.5.4) (1.16.0)\n",
      "Requirement already satisfied: gevent>=0.13 in c:\\users\\018117631\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from geventhttpclient==1.5.4) (24.2.1)\n",
      "Collecting brotli\n",
      "  Using cached Brotli-1.1.0-cp310-cp310-win_amd64.whl (357 kB)\n",
      "Collecting certifi\n",
      "  Using cached certifi-2024.2.2-py3-none-any.whl (163 kB)\n",
      "Requirement already satisfied: cffi>=1.12.2 in c:\\users\\018117631\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from gevent>=0.13->geventhttpclient==1.5.4) (1.16.0)\n",
      "Requirement already satisfied: greenlet>=2.0.0 in c:\\users\\018117631\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from gevent>=0.13->geventhttpclient==1.5.4) (3.0.3)\n",
      "Requirement already satisfied: zope.event in c:\\users\\018117631\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from gevent>=0.13->geventhttpclient==1.5.4) (5.0)\n",
      "Requirement already satisfied: zope.interface in c:\\users\\018117631\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from gevent>=0.13->geventhttpclient==1.5.4) (6.2)\n",
      "Requirement already satisfied: pycparser in c:\\users\\018117631\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from cffi>=1.12.2->gevent>=0.13->geventhttpclient==1.5.4) (2.22)\n",
      "Requirement already satisfied: setuptools in c:\\users\\018117631\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from zope.event->gevent>=0.13->geventhttpclient==1.5.4) (65.5.0)\n",
      "Installing collected packages: brotli, certifi, geventhttpclient\n",
      "Successfully installed brotli-1.1.0 certifi-2024.2.2 geventhttpclient-1.5.4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: The candidate selected for download or install is a yanked version: 'geventhttpclient' candidate (version 1.5.4 at https://files.pythonhosted.org/packages/c1/8e/7ea1039e8a1b8094030b1d1e7c6c78326c3ae48d11f45666c734ff51c3c8/geventhttpclient-1.5.4-cp310-cp310-win_amd64.whl (from https://pypi.org/simple/geventhttpclient/))\n",
      "Reason for being yanked: Accidentally introduced a backwards incompatible change see https://github.com/locustio/locust/pull/2083\n",
      "\n",
      "[notice] A new release of pip is available: 23.0.1 -> 24.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install geventhttpclient==1.5.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c40dca66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando um cliente para se comunicar com o Triton\n",
    "import tritonclient.http as httpclient\n",
    "\n",
    "triton_client = httpclient.InferenceServerClient(url=\"localhost:8000\", verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0b5d88ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GET /v2/health/live, headers {}\n",
      "<HTTPSocketPoolResponse status=200 headers={'content-length': '0', 'content-type': 'text/plain'}>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Verificar se o servidor está ativo para receber solicitações\n",
    "triton_client.is_server_live()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7ad8e25a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GET /v2/health/ready, headers {}\n",
      "<HTTPSocketPoolResponse status=200 headers={'content-length': '0', 'content-type': 'text/plain'}>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Verificar se o Triton está pronto para receber inferências\n",
    "triton_client.is_server_ready()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9adcb788",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GET /v2/models/modelo_regressao, headers {}\n",
      "<HTTPSocketPoolResponse status=200 headers={'content-type': 'application/json', 'content-length': '189'}>\n",
      "bytearray(b'{\"name\":\"modelo_regressao\",\"versions\":[\"1\"],\"platform\":\"python\",\"inputs\":[{\"name\":\"input\",\"datatype\":\"FP32\",\"shape\":[-1,-1]}],\"outputs\":[{\"name\":\"PREDICAO\",\"datatype\":\"BYTES\",\"shape\":[1]}]}')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'name': 'modelo_regressao',\n",
       " 'versions': ['1'],\n",
       " 'platform': 'python',\n",
       " 'inputs': [{'name': 'input', 'datatype': 'FP32', 'shape': [-1, -1]}],\n",
       " 'outputs': [{'name': 'PREDICAO', 'datatype': 'BYTES', 'shape': [1]}]}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Metadados do modelo \n",
    "triton_client.get_model_metadata(\"modelo_regressao\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a5dcc93",
   "metadata": {},
   "source": [
    "## Documentações\n",
    "\n",
    "https://github.com/triton-inference-server\n",
    "\n",
    "https://docs.nvidia.com/deeplearning/triton-inference-server/user-guide/docs/index.html\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
