{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5794f5ee",
   "metadata": {},
   "source": [
    "## Deploy de modelo com o Triton Inference Server"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef16ce49",
   "metadata": {},
   "source": [
    "## Pré requisitos\n",
    "- Podman\n",
    "- Notebook python"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f11fa374",
   "metadata": {},
   "source": [
    "## Explicando a estrutura dos modelos na Triton"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a1b11382",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Folder PATH listing for volume OS\n",
      "Volume serial number is 6037-BFFF\n",
      "C:\\USERS\\018117631\\DOCUMENTS\\PROJETO BB\\TRITON\\PROJETO_TRITON\\TRITON\\MODELO_REGRESSAO\n",
      "+---1\n",
      "    +---__pycache__\n"
     ]
    }
   ],
   "source": [
    "!tree modelo_regressao"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05867e6f",
   "metadata": {},
   "source": [
    "## Config.pbxt - Protobuffer\n",
    "O arquivo de de configuração do config.pbtxt especifica as entradas e saídas dos modelos:\n",
    "- As entradas são os dados que o modelo recebe para realizar a inferência. \n",
    "- As saídas são os resultados da inferência do modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "02f09f82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "backend: \"python\"\n",
      "\n",
      "input {\n",
      "    name: \"input\"\n",
      "    data_type: TYPE_FP32\n",
      "    dims: [-1, -1]\n",
      "}\n",
      "\n",
      "output {\n",
      "    name: \"PREDICAO\"\n",
      "    data_type: TYPE_STRING\n",
      "    dims: [ 1 ]\n",
      "}\n",
      "\n",
      "instance_group [{ kind: KIND_CPU }]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open('./modelo_regressao/config.pbtxt', 'r') as f:\n",
    "    arquivo_configuracao = f.read()\n",
    "\n",
    "print(arquivo_configuracao)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3abf8e4",
   "metadata": {},
   "source": [
    "## Model.py \n",
    "- O arquivo model.py contém o código para carregar o modelo com base nas configurações fornecidas pelo protobuffer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cd829f09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "import json\n",
      "\n",
      "import numpy as np\n",
      "import triton_python_backend_utils as pb_utils\n",
      "from joblib import load\n",
      "\n",
      "\n",
      "class TritonPythonModel:\n",
      "    def initialize(self, args):\n",
      "        self.model_config = model_config = json.loads(args['model_config'])\n",
      "\n",
      "        predicao_config = pb_utils.get_output_config_by_name(\n",
      "            model_config, \"PREDICAO\")\n",
      "        \n",
      "        self.predicao_dtype = pb_utils.triton_string_to_numpy(\n",
      "            predicao_config['data_type'])\n",
      "\n",
      "        version_path =  args['model_repository'] + '/' + args['model_version']\n",
      "\n",
      "        self.model = load(version_path + '/model.pickle')\n",
      "\n",
      "    def execute(self, requests):\n",
      "        responses = []\n",
      "\n",
      "        for request in requests:\n",
      "            in_0 = pb_utils.get_input_tensor_by_name(request, \"input\")\n",
      "\n",
      "            input_0 = in_0.as_numpy()\n",
      "\n",
      "            predicao = self.model.predict(input_0)\n",
      "\n",
      "            predicao_tensor = pb_utils.Tensor(\n",
      "                \"PREDICAO\", predicao.astype(self.predicao_dtype))\n",
      "\n",
      "            inference_response = pb_utils.InferenceResponse(\n",
      "                output_tensors=[predicao_tensor])\n",
      "            responses.append(inference_response)\n",
      "\n",
      "        return responses\n",
      "\n",
      "    def finalize(self):\n",
      "        print('Cleaning up...')\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open('./modelo_regressao/1/model.py', 'r') as f:\n",
    "    arquivo_modelo = f.read()\n",
    "\n",
    "print(arquivo_modelo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e72dc00e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scikit-learn===1.1.1\n",
      "  Using cached scikit_learn-1.1.1-cp310-cp310-win_amd64.whl (7.3 MB)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\018117631\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from scikit-learn===1.1.1) (3.4.0)\n",
      "Requirement already satisfied: numpy>=1.17.3 in c:\\users\\018117631\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from scikit-learn===1.1.1) (1.26.4)\n",
      "Requirement already satisfied: joblib>=1.0.0 in c:\\users\\018117631\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from scikit-learn===1.1.1) (1.4.0)\n",
      "Requirement already satisfied: scipy>=1.3.2 in c:\\users\\018117631\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from scikit-learn===1.1.1) (1.13.0)\n",
      "Installing collected packages: scikit-learn\n",
      "  Attempting uninstall: scikit-learn\n",
      "    Found existing installation: scikit-learn 1.3.0\n",
      "    Uninstalling scikit-learn-1.3.0:\n",
      "      Successfully uninstalled scikit-learn-1.3.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not install packages due to an OSError: [WinError 5] Access is denied: 'C:\\\\Users\\\\018117631\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python310\\\\Lib\\\\site-packages\\\\~-learn\\\\.libs\\\\msvcp140.dll'\n",
      "Consider using the `--user` option or check the permissions.\n",
      "\n",
      "\n",
      "[notice] A new release of pip is available: 23.0.1 -> 24.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install scikit-learn===1.1.1\n",
    "# !pip install scikit-learn===0.24.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1d0048ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" import pickle\\ndict_pickle_in = open('./modelo_regressao/1/model.pickle','rb')\\ndict1 = pickle.load(dict_pickle_in)\\ntype(dict1) \""
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Deserializando .pickle do modelo para entender o tipo de modelo\n",
    "\n",
    "\"\"\" import pickle\n",
    "dict_pickle_in = open('./modelo_regressao/1/model.pickle','rb')\n",
    "dict1 = pickle.load(dict_pickle_in)\n",
    "type(dict1) \"\"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62585c81",
   "metadata": {},
   "source": [
    "## Deploy do modelo na triton usando o podman"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55792a2b",
   "metadata": {},
   "source": [
    "Imagem do triton mais recente: 23.09-py3\n",
    "\n",
    "`podman pull nvcr.io/nvidia/tritonserver:23.09-py3`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfbaa038",
   "metadata": {},
   "source": [
    "No terminal, executar o comando:\n",
    "\n",
    "`podman run --rm -p 8000:8000 -v $HOME/triton:/models nvcr.io/nvidia/tritonserver:23.09-py3 /bin/bash -c \"pip install -r /models/requirements.txt && tritonserver --model-repository=/models\"`\n",
    "\n",
    "\n",
    "O que faz esse comado:\n",
    "\n",
    "- Executa um contêiner usando o podman, mapeando a porta 8000 do host para a porta 8000 do contêiner e montando o diretório $HOME/triton do host para /models dentro do contêiner. \n",
    "- Instala o requirements (bibliotecas necessárias) para o modelo."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd6cd360",
   "metadata": {},
   "source": [
    "## Após o deploy, vamos realizar inferências!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "68fcffb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[11.1]]\n",
      "{\"model_name\":\"modelo_regressao\",\"model_version\":\"1\",\"outputs\":[{\"name\":\"PREDICAO\",\"datatype\":\"BYTES\",\"shape\":[1],\"data\":[\"121873.0\"]}]}\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "import numpy as np\n",
    "\n",
    "url = \"http://localhost:8000/v2/models/modelo_regressao/versions/1/infer\"\n",
    "\n",
    "\n",
    "# input data\n",
    "input_data = np.array([11.1]).reshape(-1, 1)\n",
    "# input_data = np.array([10.1]).reshape(-1, 1)\n",
    "print(input_data)\n",
    "payload = json.dumps({\n",
    "  \"inputs\": [\n",
    "    {\n",
    "      # \"name\": \"ENTRADA\",\n",
    "      \"name\": \"input\",\n",
    "      \"shape\": input_data.shape,\n",
    "      \"datatype\": \"FP32\",\n",
    "      \"data\": input_data.tolist()\n",
    "    }\n",
    "  ]\n",
    "})\n",
    "\n",
    "headers = {\n",
    "  'Content-Type': 'application/json'\n",
    "}\n",
    "\n",
    "response = requests.request(\"POST\", url, headers=headers, data=payload)\n",
    "\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dd0ed15",
   "metadata": {},
   "source": [
    "## Comandinhos de verificação"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac49923b",
   "metadata": {},
   "source": [
    "> É necessário utilizar a versão 3.10.11 do Python para instalar as bibiliotecas a seguir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdfed8d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tritonclient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "799c0807",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install gevent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9f42206a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting geventhttpclient==1.5.4\n",
      "  Downloading geventhttpclient-1.5.4-cp310-cp310-win_amd64.whl (37 kB)\n",
      "Requirement already satisfied: six in c:\\users\\018117631\\appdata\\roaming\\python\\python310\\site-packages (from geventhttpclient==1.5.4) (1.16.0)\n",
      "Requirement already satisfied: gevent>=0.13 in c:\\users\\018117631\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from geventhttpclient==1.5.4) (24.2.1)\n",
      "Collecting brotli\n",
      "  Using cached Brotli-1.1.0-cp310-cp310-win_amd64.whl (357 kB)\n",
      "Collecting certifi\n",
      "  Using cached certifi-2024.2.2-py3-none-any.whl (163 kB)\n",
      "Requirement already satisfied: cffi>=1.12.2 in c:\\users\\018117631\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from gevent>=0.13->geventhttpclient==1.5.4) (1.16.0)\n",
      "Requirement already satisfied: greenlet>=2.0.0 in c:\\users\\018117631\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from gevent>=0.13->geventhttpclient==1.5.4) (3.0.3)\n",
      "Requirement already satisfied: zope.event in c:\\users\\018117631\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from gevent>=0.13->geventhttpclient==1.5.4) (5.0)\n",
      "Requirement already satisfied: zope.interface in c:\\users\\018117631\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from gevent>=0.13->geventhttpclient==1.5.4) (6.2)\n",
      "Requirement already satisfied: pycparser in c:\\users\\018117631\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from cffi>=1.12.2->gevent>=0.13->geventhttpclient==1.5.4) (2.22)\n",
      "Requirement already satisfied: setuptools in c:\\users\\018117631\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from zope.event->gevent>=0.13->geventhttpclient==1.5.4) (65.5.0)\n",
      "Installing collected packages: brotli, certifi, geventhttpclient\n",
      "Successfully installed brotli-1.1.0 certifi-2024.2.2 geventhttpclient-1.5.4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: The candidate selected for download or install is a yanked version: 'geventhttpclient' candidate (version 1.5.4 at https://files.pythonhosted.org/packages/c1/8e/7ea1039e8a1b8094030b1d1e7c6c78326c3ae48d11f45666c734ff51c3c8/geventhttpclient-1.5.4-cp310-cp310-win_amd64.whl (from https://pypi.org/simple/geventhttpclient/))\n",
      "Reason for being yanked: Accidentally introduced a backwards incompatible change see https://github.com/locustio/locust/pull/2083\n",
      "\n",
      "[notice] A new release of pip is available: 23.0.1 -> 24.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install geventhttpclient==1.5.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c40dca66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando um cliente para se comunicar com o Triton\n",
    "import tritonclient.http as httpclient\n",
    "\n",
    "triton_client = httpclient.InferenceServerClient(url=\"localhost:8000\", verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0b5d88ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GET /v2/health/live, headers {}\n",
      "<HTTPSocketPoolResponse status=200 headers={'content-length': '0', 'content-type': 'text/plain'}>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Verificar se o servidor está ativo para receber solicitações\n",
    "triton_client.is_server_live()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7ad8e25a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GET /v2/health/ready, headers {}\n",
      "<HTTPSocketPoolResponse status=200 headers={'content-length': '0', 'content-type': 'text/plain'}>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Verificar se o Triton está pronto para receber inferências\n",
    "triton_client.is_server_ready()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9adcb788",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GET /v2/models/modelo_regressao, headers {}\n",
      "<HTTPSocketPoolResponse status=200 headers={'content-type': 'application/json', 'content-length': '189'}>\n",
      "bytearray(b'{\"name\":\"modelo_regressao\",\"versions\":[\"1\"],\"platform\":\"python\",\"inputs\":[{\"name\":\"input\",\"datatype\":\"FP32\",\"shape\":[-1,-1]}],\"outputs\":[{\"name\":\"PREDICAO\",\"datatype\":\"BYTES\",\"shape\":[1]}]}')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'name': 'modelo_regressao',\n",
       " 'versions': ['1'],\n",
       " 'platform': 'python',\n",
       " 'inputs': [{'name': 'input', 'datatype': 'FP32', 'shape': [-1, -1]}],\n",
       " 'outputs': [{'name': 'PREDICAO', 'datatype': 'BYTES', 'shape': [1]}]}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Metadados do modelo \n",
    "triton_client.get_model_metadata(\"modelo_regressao\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a5dcc93",
   "metadata": {},
   "source": [
    "## Documentações\n",
    "\n",
    "https://github.com/triton-inference-server\n",
    "\n",
    "https://docs.nvidia.com/deeplearning/triton-inference-server/user-guide/docs/index.html\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
